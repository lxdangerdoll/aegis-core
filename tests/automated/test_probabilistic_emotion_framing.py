#!/usr/bin/env python3
"""
Test: Probabilistic Emotion Framing in System Prompts

Validates that emotion detection is presented to the LLM as probabilistic data
requiring validation, not absolute truth.

Bug Fix: https://github.com/whisperengine-ai/whisperengine/issues/XXX
User reported Aetheris making declarative statements about emotions that were incorrect.
"""

import asyncio
import os
import sys
from typing import Dict, Any

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from src.prompts.cdl_ai_integration import CDLAIPromptIntegration


async def test_emotion_framing():
    """Test that emotion prompts use probabilistic framing"""
    
    print("=" * 80)
    print("TEST: Probabilistic Emotion Framing in System Prompts")
    print("=" * 80)
    print()
    
    cdl_integration = CDLAIPromptIntegration()
    
    # Test scenarios with different confidence levels
    test_cases = [
        {
            "name": "High Confidence Joy (95%)",
            "emotion_data": {
                "primary_emotion": "joy",
                "intensity": 0.8,
                "confidence": 0.95,
                "multi_modal": True,
                "secondary_emotions": ["optimism"],
                "emotional_trajectory": ["intensifying"],
                "cultural_context": None
            },
            "expected_contains": [
                "EMOTION READING (PROBABILISTIC)",
                "confidence: 0.95",
                "‚ö†Ô∏è UNCERTAINTY NOTE: Emotion detection is probabilistic",
                "Still use tentative phrasing",
                "Never state user emotions as absolute fact"
            ],
            "must_not_contain": [
                "USER EMOTIONAL STATE",
                "high accuracy",
                "feeling the joy radiating",
                "You carry joy"
            ]
        },
        {
            "name": "Moderate Confidence Sadness (75%)",
            "emotion_data": {
                "primary_emotion": "sadness",
                "intensity": 0.6,
                "confidence": 0.75,
                "multi_modal": True,
                "secondary_emotions": [],
                "emotional_trajectory": [],
                "cultural_context": None
            },
            "expected_contains": [
                "EMOTION READING (PROBABILISTIC)",
                "confidence: 0.75",
                "MODERATE CONFIDENCE",
                "Use gentle observational language",
                "you seem",
                "I'm picking up"
            ],
            "must_not_contain": [
                "USER EMOTIONAL STATE",
                "absolute",
                "definitely",
                "clearly"
            ]
        },
        {
            "name": "Low Confidence Neutral (60%)",
            "emotion_data": {
                "primary_emotion": "neutral",
                "intensity": 0.4,
                "confidence": 0.60,
                "multi_modal": False,
                "secondary_emotions": [],
                "emotional_trajectory": [],
                "cultural_context": None
            },
            "expected_contains": [
                "EMOTION READING (PROBABILISTIC)",
                "confidence: 0.60",
                "LOW CONFIDENCE",
                "Use tentative language",
                "I sense",
                "it seems"
            ],
            "must_not_contain": [
                "USER EMOTIONAL STATE",
                "high accuracy",
                "Multi-modal"
            ]
        }
    ]
    
    all_passed = True
    
    for test_case in test_cases:
        print(f"Testing: {test_case['name']}")
        print("-" * 80)
        
        # Create a minimal system prompt with emotion data
        try:
            # We'll test the emotion section formatting directly
            # by simulating what _build_unified_prompt does
            emotion_data = test_case["emotion_data"]
            
            # Build the emotion section (extracted logic from cdl_ai_integration.py)
            prompt = ""
            primary_emotion = emotion_data.get('primary_emotion', 'neutral')
            confidence = emotion_data.get('confidence', 0.5)
            secondary_emotions = emotion_data.get('secondary_emotions', [])
            emotional_trajectory = emotion_data.get('emotional_trajectory', [])
            cultural_context = emotion_data.get('cultural_context')
            is_multi_modal = emotion_data.get('multi_modal', False)
            
            # Build rich emotional context prompt with probabilistic framing
            if secondary_emotions and len(secondary_emotions) > 0:
                secondary_str = ', '.join(secondary_emotions[:2])
                prompt += f"\n\nüé≠ EMOTION READING (PROBABILISTIC): {primary_emotion} with undertones of {secondary_str} (confidence: {confidence:.2f})"
            else:
                prompt += f"\n\nüé≠ EMOTION READING (PROBABILISTIC): {primary_emotion} (confidence: {confidence:.2f})"
            
            # Add multi-modal analysis indicator
            if is_multi_modal:
                prompt += f"\nüì± ANALYSIS METHOD: Multi-modal detection (text + emoji + patterns)"
            
            # CRITICAL: Emphasize probabilistic nature
            prompt += f"\n‚ö†Ô∏è UNCERTAINTY NOTE: Emotion detection is probabilistic. Validate through conversation."
            if confidence < 0.7:
                prompt += f"\nüí° LOW CONFIDENCE: Use tentative language ('I sense...', 'it seems...') and invite user to share their actual state."
            elif confidence < 0.85:
                prompt += f"\nüí° MODERATE CONFIDENCE: Use gentle observational language ('you seem...', 'I'm picking up...') rather than declarative statements."
            else:
                prompt += f"\nüí° HIGH CONFIDENCE: Still use tentative phrasing ('I sense...', 'there's a...') to avoid assumptions. Never state user emotions as absolute fact."
            
            # Add emotional trajectory context
            if emotional_trajectory and len(emotional_trajectory) > 0:
                trajectory_pattern = emotional_trajectory[-1] if emotional_trajectory else 'stable'
                if trajectory_pattern in ['intensifying', 'escalating']:
                    prompt += f"\nüìà EMOTIONAL TREND: Their emotions may be intensifying - respond with extra sensitivity"
                elif trajectory_pattern in ['calming', 'settling']:
                    prompt += f"\nüìâ EMOTIONAL TREND: Their emotions may be calming - provide gentle support"
                elif trajectory_pattern in ['fluctuating', 'mixed']:
                    prompt += f"\nüåä EMOTIONAL TREND: Complex emotional state detected - be especially attentive to nuances"
            
            # Add cultural context awareness
            if cultural_context and isinstance(cultural_context, dict):
                expression_style = cultural_context.get('expression_style', '')
                if expression_style == 'direct':
                    prompt += f"\nüó∫Ô∏è CULTURAL CONTEXT: Direct communication style - be clear and straightforward"
                elif expression_style == 'indirect':
                    prompt += f"\nüó∫Ô∏è CULTURAL CONTEXT: Indirect communication style - read between the lines"
            elif cultural_context and isinstance(cultural_context, str):
                prompt += f"\nüó∫Ô∏è CULTURAL CONTEXT: {cultural_context} communication style"
            
            prompt += f"\n\nüí¨ EMPATHY GUIDANCE: Respond with nuanced empathy matching their emotional complexity and communication style."
            
            print("Generated Emotion Section:")
            print(prompt)
            print()
            
            # Validate expected content
            test_passed = True
            for expected in test_case["expected_contains"]:
                if expected not in prompt:
                    print(f"‚ùå MISSING: '{expected}'")
                    test_passed = False
                    all_passed = False
            
            # Validate prohibited content
            for prohibited in test_case["must_not_contain"]:
                if prohibited in prompt:
                    print(f"‚ùå FOUND PROHIBITED: '{prohibited}'")
                    test_passed = False
                    all_passed = False
            
            if test_passed:
                print(f"‚úÖ PASSED: {test_case['name']}")
            else:
                print(f"‚ùå FAILED: {test_case['name']}")
            
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False
        
        print()
    
    print("=" * 80)
    if all_passed:
        print("‚úÖ ALL TESTS PASSED")
        print()
        print("Emotion framing now uses probabilistic language and guides the LLM to:")
        print("  ‚Ä¢ Use tentative phrasing ('I sense...', 'it seems...')")
        print("  ‚Ä¢ Avoid declarative statements about user emotions")
        print("  ‚Ä¢ Validate emotion readings through conversation")
        print("  ‚Ä¢ Never state emotions as absolute fact")
    else:
        print("‚ùå SOME TESTS FAILED")
    print("=" * 80)
    
    return all_passed


if __name__ == "__main__":
    result = asyncio.run(test_emotion_framing())
    sys.exit(0 if result else 1)
