"""
Memory Effectiveness Analyzer - Sprint 2: MemoryBoost

Analyzes memory performance based on conversation outcomes to optimize
vector memory retrieval and quality scoring. Integrates with TrendWise
to correlate memory patterns with conversation success.

Core Features:
- Memory pattern effectiveness analysis
- Conversation outcome correlation
- Vector quality scoring
- Real-time memory optimization
- Integration with TrendWise analytics

This component transforms WhisperEngine from passive memory storage
to intelligent memory optimization based on actual conversation results.
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
from statistics import mean, stdev
import json

logger = logging.getLogger(__name__)


class MemoryPattern(Enum):
    """Types of memory patterns that can be analyzed for effectiveness"""
    FACTUAL_RECALL = "factual_recall"
    EMOTIONAL_CONTEXT = "emotional_context"
    CONVERSATION_HISTORY = "conversation_history"
    PREFERENCE_MEMORY = "preference_memory"
    RELATIONSHIP_CONTEXT = "relationship_context"
    TECHNICAL_KNOWLEDGE = "technical_knowledge"
    CREATIVE_INSPIRATION = "creative_inspiration"


class ConversationOutcome(Enum):
    """Conversation quality outcomes for correlation analysis"""
    EXCELLENT = "excellent"        # High engagement, positive sentiment
    GOOD = "good"                 # Satisfactory interaction
    AVERAGE = "average"           # Standard interaction
    POOR = "poor"                 # Low engagement, issues
    FAILED = "failed"             # Conversation breakdown


@dataclass
class MemoryEffectivenessMetrics:
    """Metrics for memory pattern effectiveness"""
    pattern_type: MemoryPattern
    usage_count: int
    success_rate: float           # Percentage of successful conversations when pattern used
    average_outcome_score: float  # Average conversation quality score (0-1)
    improvement_factor: float     # Improvement vs. baseline without this pattern
    confidence_boost: float       # Confidence improvement when pattern matches
    user_satisfaction: float      # User satisfaction correlation (0-1)
    response_relevance: float     # Response relevance when pattern used
    last_updated: datetime


@dataclass
class MemoryQualityScore:
    """Quality scoring for individual memories"""
    memory_id: str
    user_id: str
    bot_name: str
    content_relevance: float      # How relevant content is (0-1)
    outcome_correlation: float    # Correlation with positive outcomes (0-1)
    usage_frequency: float        # How often memory is retrieved (0-1)
    temporal_relevance: float     # Recency and timing relevance (0-1)
    emotional_impact: float       # Emotional relevance and impact (0-1)
    combined_score: float         # Overall quality score (0-1)
    boost_factor: float           # Recommended boost/penalty factor
    last_analyzed: datetime


@dataclass
class ConversationAnalysis:
    """Analysis of conversation outcomes for memory correlation"""
    conversation_id: str
    user_id: str
    bot_name: str
    outcome: ConversationOutcome
    quality_score: float
    confidence_score: float
    memories_used: List[str]      # Memory IDs referenced
    memory_patterns: List[MemoryPattern]
    sentiment_score: float
    engagement_score: float
    timestamp: datetime


class MemoryEffectivenessAnalyzer:
    """
    Analyzes memory performance based on conversation outcomes to optimize
    vector memory retrieval and implement intelligent quality scoring.
    
    Integrates with TrendWise to correlate memory patterns with conversation
    success metrics from InfluxDB analytics.
    """
    
    def __init__(self, memory_manager=None, trend_analyzer=None, temporal_client=None):
        """
        Initialize memory effectiveness analyzer.
        
        Args:
            memory_manager: Vector memory system instance
            trend_analyzer: TrendWise InfluxDB analyzer
            temporal_client: InfluxDB client for metrics storage
        """
        self.memory_manager = memory_manager
        self.trend_analyzer = trend_analyzer
        self.temporal_client = temporal_client
        self.logger = logger
        
        # Analysis parameters
        self.min_sample_size = 10
        self.analysis_window_days = 14
        self.quality_threshold = 0.7
        self.boost_threshold = 0.8
        self.penalty_threshold = 0.3
        
        # Cache for effectiveness metrics
        self._effectiveness_cache = {}
        self._cache_duration_hours = 2
        
    async def analyze_memory_performance(
        self, 
        user_id: str, 
        bot_name: str = None,
        days_back: int = 14
    ) -> Dict[MemoryPattern, MemoryEffectivenessMetrics]:
        """
        Analyze memory performance patterns based on conversation outcomes.
        
        Args:
            user_id: User identifier for analysis
            bot_name: Bot name (optional, analyzes all if None)
            days_back: Days of history to analyze
            
        Returns:
            Dictionary mapping memory patterns to effectiveness metrics
        """
        try:
            self.logger.info(f"ðŸ§  Analyzing memory performance for user {user_id}, bot {bot_name}")
            
            # Get conversation outcomes from TrendWise analytics
            conversation_analyses = await self._get_conversation_analyses(
                user_id, bot_name, days_back
            )
            
            if len(conversation_analyses) < self.min_sample_size:
                self.logger.warning(f"Insufficient data for analysis: {len(conversation_analyses)} conversations")
                return {}
            
            # Analyze each memory pattern
            pattern_metrics = {}
            for pattern in MemoryPattern:
                metrics = await self._analyze_pattern_effectiveness(
                    pattern, conversation_analyses, user_id, bot_name
                )
                if metrics:
                    pattern_metrics[pattern] = metrics
            
            # Store metrics in InfluxDB for trend analysis
            await self._store_effectiveness_metrics(pattern_metrics, user_id, bot_name)
            
            self.logger.info(f"ðŸ“Š Analyzed {len(pattern_metrics)} memory patterns")
            return pattern_metrics
            
        except Exception as e:
            self.logger.error(f"Error analyzing memory performance: {e}")
            return {}
    
    async def score_memory_quality(
        self,
        memory_id: str,
        user_id: str,
        bot_name: str,
        memory_content: str,
        memory_type: str
    ) -> MemoryQualityScore:
        """
        Score individual memory quality based on usage patterns and outcomes.
        
        Args:
            memory_id: Unique memory identifier
            user_id: User who owns the memory
            bot_name: Bot associated with memory
            memory_content: Content of the memory
            memory_type: Type of memory (conversation, fact, etc.)
            
        Returns:
            Quality score with optimization recommendations
        """
        try:
            # Get usage statistics for this memory
            usage_stats = await self._get_memory_usage_stats(memory_id, user_id, bot_name)
            
            # Analyze conversation outcomes when this memory was used
            outcome_correlation = await self._calculate_outcome_correlation(
                memory_id, user_id, bot_name
            )
            
            # Calculate relevance scores
            content_relevance = await self._calculate_content_relevance(
                memory_content, memory_type, user_id, bot_name
            )
            
            temporal_relevance = self._calculate_temporal_relevance(usage_stats)
            emotional_impact = await self._calculate_emotional_impact(
                memory_content, user_id, bot_name
            )
            
            # Combined quality score
            combined_score = self._calculate_combined_quality_score(
                content_relevance, outcome_correlation, usage_stats['frequency'],
                temporal_relevance, emotional_impact
            )
            
            # Determine boost/penalty factor
            boost_factor = self._calculate_boost_factor(combined_score, outcome_correlation)
            
            return MemoryQualityScore(
                memory_id=memory_id,
                user_id=user_id,
                bot_name=bot_name,
                content_relevance=content_relevance,
                outcome_correlation=outcome_correlation,
                usage_frequency=usage_stats['frequency'],
                temporal_relevance=temporal_relevance,
                emotional_impact=emotional_impact,
                combined_score=combined_score,
                boost_factor=boost_factor,
                last_analyzed=datetime.now()
            )
            
        except Exception as e:
            self.logger.error(f"Error scoring memory quality for {memory_id}: {e}")
            return self._default_quality_score(memory_id, user_id, bot_name)
    
    async def get_memory_optimization_recommendations(
        self,
        user_id: str,
        bot_name: str,
        conversation_context: str = None
    ) -> Dict[str, Any]:
        """
        Get specific recommendations for memory retrieval optimization.
        
        Args:
            user_id: User identifier
            bot_name: Bot name
            conversation_context: Current conversation context
            
        Returns:
            Dictionary with optimization recommendations
        """
        try:
            # Get recent effectiveness analysis
            effectiveness_metrics = await self.analyze_memory_performance(
                user_id, bot_name, days_back=7
            )
            
            # Identify high-performing patterns
            high_performers = {
                pattern: metrics for pattern, metrics in effectiveness_metrics.items()
                if metrics.success_rate > self.boost_threshold
            }
            
            # Identify underperforming patterns
            underperformers = {
                pattern: metrics for pattern, metrics in effectiveness_metrics.items()
                if metrics.success_rate < self.penalty_threshold
            }
            
            # Generate context-specific recommendations
            recommendations = {
                'boost_patterns': list(high_performers.keys()),
                'penalty_patterns': list(underperformers.keys()),
                'retrieve_more': await self._get_retrieval_recommendations(
                    high_performers, conversation_context
                ),
                'retrieve_less': list(underperformers.keys()),
                'quality_threshold': self._calculate_dynamic_quality_threshold(effectiveness_metrics),
                'memory_limit_adjustment': self._calculate_memory_limit_adjustment(effectiveness_metrics),
                'analysis_timestamp': datetime.now(),
                'confidence': self._calculate_recommendation_confidence(effectiveness_metrics)
            }
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"Error generating memory optimization recommendations: {e}")
            return self._default_recommendations()
    
    async def _get_conversation_analyses(
        self,
        user_id: str,
        bot_name: str,
        days_back: int
    ) -> List[ConversationAnalysis]:
        """Get conversation analyses from TrendWise analytics."""
        try:
            analyses = []
            
            if not self.trend_analyzer or not self.temporal_client:
                self.logger.warning("TrendWise components not available, using fallback analysis")
                return await self._fallback_conversation_analysis(user_id, bot_name, days_back)
            
            # Get conversation quality trends from TrendWise
            confidence_trends = await self.trend_analyzer.get_confidence_trends(
                bot_name, user_id, days_back
            )
            
            # Get detailed conversation metrics from InfluxDB
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days_back)
            
            query = f'''
            SELECT *
            FROM conversation_metrics
            WHERE time >= '{start_time.isoformat()}'
            AND time <= '{end_time.isoformat()}'
            AND user_id = '{user_id}'
            '''
            
            if bot_name:
                query += f" AND bot_name = '{bot_name}'"
            
            result = await self.temporal_client.query(query)
            
            # Convert to ConversationAnalysis objects
            for point in result['series'][0]['values'] if result.get('series') else []:
                analysis = self._parse_conversation_metrics(point)
                if analysis:
                    analyses.append(analysis)
            
            return analyses
            
        except Exception as e:
            self.logger.error(f"Error getting conversation analyses: {e}")
            return []
    
    async def _analyze_pattern_effectiveness(
        self,
        pattern: MemoryPattern,
        conversation_analyses: List[ConversationAnalysis],
        user_id: str,
        bot_name: str
    ) -> Optional[MemoryEffectivenessMetrics]:
        """Analyze effectiveness of specific memory pattern."""
        try:
            # Filter conversations that used this pattern
            pattern_conversations = [
                conv for conv in conversation_analyses
                if pattern in conv.memory_patterns
            ]
            
            if len(pattern_conversations) < self.min_sample_size:
                return None
            
            # Calculate metrics
            usage_count = len(pattern_conversations)
            success_rate = len([conv for conv in pattern_conversations if conv.outcome in [ConversationOutcome.EXCELLENT, ConversationOutcome.GOOD]]) / usage_count
            average_outcome_score = mean([conv.quality_score for conv in pattern_conversations])
            
            # Calculate improvement vs baseline (conversations without this pattern)
            baseline_conversations = [
                conv for conv in conversation_analyses
                if pattern not in conv.memory_patterns
            ]
            
            if baseline_conversations:
                baseline_score = mean([conv.quality_score for conv in baseline_conversations])
                improvement_factor = average_outcome_score / baseline_score if baseline_score > 0 else 1.0
            else:
                improvement_factor = 1.0
            
            confidence_boost = mean([conv.confidence_score for conv in pattern_conversations])
            user_satisfaction = success_rate  # Simplified correlation
            response_relevance = average_outcome_score  # Simplified correlation
            
            return MemoryEffectivenessMetrics(
                pattern_type=pattern,
                usage_count=usage_count,
                success_rate=success_rate,
                average_outcome_score=average_outcome_score,
                improvement_factor=improvement_factor,
                confidence_boost=confidence_boost,
                user_satisfaction=user_satisfaction,
                response_relevance=response_relevance,
                last_updated=datetime.now()
            )
            
        except Exception as e:
            self.logger.error(f"Error analyzing pattern {pattern} effectiveness: {e}")
            return None
    
    async def _get_memory_usage_stats(
        self,
        memory_id: str,
        user_id: str,
        bot_name: str
    ) -> Dict[str, Any]:
        """Get usage statistics for a specific memory."""
        try:
            # Default stats structure
            stats = {
                'frequency': 0.5,  # Default medium frequency
                'last_used': datetime.now() - timedelta(days=7),
                'total_retrievals': 10,
                'successful_retrievals': 7
            }
            
            # If we have access to memory manager, get real stats
            if self.memory_manager:
                # This would require adding usage tracking to memory system
                # For now, use simplified estimation
                pass
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Error getting memory usage stats: {e}")
            return {'frequency': 0.5, 'last_used': datetime.now(), 'total_retrievals': 1, 'successful_retrievals': 1}
    
    async def _calculate_outcome_correlation(
        self,
        memory_id: str,
        user_id: str,
        bot_name: str
    ) -> float:
        """Calculate correlation between memory usage and positive outcomes."""
        try:
            # Simplified correlation calculation
            # In production, this would analyze conversation outcomes when memory was used
            return 0.7  # Default positive correlation
            
        except Exception as e:
            self.logger.error(f"Error calculating outcome correlation: {e}")
            return 0.5
    
    async def _calculate_content_relevance(
        self,
        memory_content: str,
        memory_type: str,
        user_id: str,
        bot_name: str
    ) -> float:
        """Calculate content relevance score."""
        try:
            # Simplified relevance calculation
            # Consider memory type, recency, content quality
            base_relevance = 0.6
            
            # Boost for certain memory types
            if memory_type in ['fact', 'preference', 'relationship']:
                base_relevance += 0.2
            
            # Content length and quality indicators
            if memory_content and len(memory_content) > 20:
                base_relevance += 0.1
            
            return min(base_relevance, 1.0)
            
        except Exception as e:
            self.logger.error(f"Error calculating content relevance: {e}")
            return 0.5
    
    def _calculate_temporal_relevance(self, usage_stats: Dict[str, Any]) -> float:
        """Calculate temporal relevance based on recency and usage patterns."""
        try:
            last_used = usage_stats.get('last_used', datetime.now() - timedelta(days=30))
            days_since_used = (datetime.now() - last_used).days
            
            # Exponential decay based on recency
            temporal_relevance = max(0.1, 1.0 * (0.95 ** days_since_used))
            
            return temporal_relevance
            
        except Exception as e:
            self.logger.error(f"Error calculating temporal relevance: {e}")
            return 0.5
    
    async def _calculate_emotional_impact(
        self,
        memory_content: str,
        user_id: str,
        bot_name: str
    ) -> float:
        """Calculate emotional impact score for memory."""
        try:
            # Simplified emotional impact calculation
            # Look for emotional keywords, sentiment indicators
            emotional_keywords = ['love', 'hate', 'happy', 'sad', 'excited', 'worried', 'important', 'special']
            
            content_lower = memory_content.lower()
            emotional_score = sum(1 for keyword in emotional_keywords if keyword in content_lower)
            
            # Normalize to 0-1 scale
            return min(emotional_score / 10.0, 1.0)
            
        except Exception as e:
            self.logger.error(f"Error calculating emotional impact: {e}")
            return 0.3
    
    def _calculate_combined_quality_score(
        self,
        content_relevance: float,
        outcome_correlation: float,
        usage_frequency: float,
        temporal_relevance: float,
        emotional_impact: float
    ) -> float:
        """Calculate combined quality score with weighted factors."""
        try:
            # Weighted combination of factors
            weights = {
                'content': 0.25,
                'outcome': 0.30,
                'frequency': 0.20,
                'temporal': 0.15,
                'emotional': 0.10
            }
            
            combined_score = (
                content_relevance * weights['content'] +
                outcome_correlation * weights['outcome'] +
                usage_frequency * weights['frequency'] +
                temporal_relevance * weights['temporal'] +
                emotional_impact * weights['emotional']
            )
            
            return max(0.0, min(1.0, combined_score))
            
        except Exception as e:
            self.logger.error(f"Error calculating combined quality score: {e}")
            return 0.5
    
    def _calculate_boost_factor(self, quality_score: float, outcome_correlation: float) -> float:
        """Calculate boost/penalty factor for memory retrieval."""
        try:
            # Base boost factor from quality score
            if quality_score > self.boost_threshold:
                boost_factor = 1.0 + (quality_score - self.boost_threshold) * 2.0
            elif quality_score < self.penalty_threshold:
                boost_factor = 0.5 + (quality_score / self.penalty_threshold) * 0.5
            else:
                boost_factor = 1.0
            
            # Additional boost from outcome correlation
            if outcome_correlation > 0.8:
                boost_factor *= 1.2
            elif outcome_correlation < 0.3:
                boost_factor *= 0.8
            
            return max(0.1, min(3.0, boost_factor))
            
        except Exception as e:
            self.logger.error(f"Error calculating boost factor: {e}")
            return 1.0
    
    def _default_quality_score(self, memory_id: str, user_id: str, bot_name: str) -> MemoryQualityScore:
        """Return default quality score when analysis fails."""
        return MemoryQualityScore(
            memory_id=memory_id,
            user_id=user_id,
            bot_name=bot_name,
            content_relevance=0.5,
            outcome_correlation=0.5,
            usage_frequency=0.5,
            temporal_relevance=0.5,
            emotional_impact=0.3,
            combined_score=0.46,
            boost_factor=1.0,
            last_analyzed=datetime.now()
        )
    
    async def _fallback_conversation_analysis(
        self,
        user_id: str,
        bot_name: str,
        days_back: int
    ) -> List[ConversationAnalysis]:
        """Fallback conversation analysis when TrendWise is not available."""
        try:
            # Create synthetic conversation analyses for testing
            analyses = []
            
            for i in range(15):  # Generate 15 test conversations
                analysis = ConversationAnalysis(
                    conversation_id=f"conv_{i}",
                    user_id=user_id,
                    bot_name=bot_name or "test_bot",
                    outcome=ConversationOutcome.GOOD if i % 3 != 0 else ConversationOutcome.AVERAGE,
                    quality_score=0.6 + (i % 5) * 0.08,
                    confidence_score=0.7 + (i % 4) * 0.05,
                    memories_used=[f"mem_{i}", f"mem_{i+1}"],
                    memory_patterns=[MemoryPattern.CONVERSATION_HISTORY, MemoryPattern.EMOTIONAL_CONTEXT],
                    sentiment_score=0.6 + (i % 6) * 0.06,
                    engagement_score=0.65 + (i % 7) * 0.05,
                    timestamp=datetime.now() - timedelta(days=i)
                )
                analyses.append(analysis)
            
            return analyses
            
        except Exception as e:
            self.logger.error(f"Error in fallback conversation analysis: {e}")
            return []
    
    def _parse_conversation_metrics(self, point: List[Any]) -> Optional[ConversationAnalysis]:
        """Parse InfluxDB point to ConversationAnalysis."""
        try:
            # Simplified parsing - in production would match InfluxDB schema
            return ConversationAnalysis(
                conversation_id=f"conv_{point[0]}",
                user_id=str(point[1]),
                bot_name=str(point[2]),
                outcome=ConversationOutcome.GOOD,
                quality_score=float(point[3]) if len(point) > 3 else 0.7,
                confidence_score=float(point[4]) if len(point) > 4 else 0.7,
                memories_used=[],
                memory_patterns=[MemoryPattern.CONVERSATION_HISTORY],
                sentiment_score=0.7,
                engagement_score=0.7,
                timestamp=datetime.now()
            )
        except Exception as e:
            self.logger.error(f"Error parsing conversation metrics: {e}")
            return None
    
    async def _store_effectiveness_metrics(
        self,
        metrics: Dict[MemoryPattern, MemoryEffectivenessMetrics],
        user_id: str,
        bot_name: str
    ) -> None:
        """Store effectiveness metrics in InfluxDB."""
        try:
            if not self.temporal_client:
                return
            
            # Store metrics for trend analysis
            for pattern, metric in metrics.items():
                point = {
                    'measurement': 'memory_effectiveness',
                    'tags': {
                        'user_id': user_id,
                        'bot_name': bot_name,
                        'pattern': pattern.value
                    },
                    'fields': {
                        'success_rate': metric.success_rate,
                        'usage_count': metric.usage_count,
                        'improvement_factor': metric.improvement_factor,
                        'confidence_boost': metric.confidence_boost
                    },
                    'time': datetime.now()
                }
                
                await self.temporal_client.write_point(point)
                
        except Exception as e:
            self.logger.error(f"Error storing effectiveness metrics: {e}")
    
    async def _get_retrieval_recommendations(
        self,
        high_performers: Dict[MemoryPattern, MemoryEffectivenessMetrics],
        conversation_context: str
    ) -> List[MemoryPattern]:
        """Get specific retrieval recommendations based on context."""
        try:
            recommendations = []
            
            # Context-aware recommendations
            if conversation_context:
                context_lower = conversation_context.lower()
                
                if any(word in context_lower for word in ['feel', 'emotion', 'mood']):
                    recommendations.append(MemoryPattern.EMOTIONAL_CONTEXT)
                
                if any(word in context_lower for word in ['remember', 'recall', 'before']):
                    recommendations.append(MemoryPattern.CONVERSATION_HISTORY)
                
                if any(word in context_lower for word in ['like', 'prefer', 'favorite']):
                    recommendations.append(MemoryPattern.PREFERENCE_MEMORY)
            
            # Add high-performing patterns
            recommendations.extend(list(high_performers.keys())[:3])
            
            return list(set(recommendations))  # Remove duplicates
            
        except Exception as e:
            self.logger.error(f"Error getting retrieval recommendations: {e}")
            return []
    
    def _calculate_dynamic_quality_threshold(
        self,
        effectiveness_metrics: Dict[MemoryPattern, MemoryEffectivenessMetrics]
    ) -> float:
        """Calculate dynamic quality threshold based on current effectiveness."""
        try:
            if not effectiveness_metrics:
                return self.quality_threshold
            
            avg_success_rate = mean([m.success_rate for m in effectiveness_metrics.values()])
            
            # Adjust threshold based on average performance
            if avg_success_rate > 0.8:
                return self.quality_threshold + 0.1  # Raise bar when performing well
            elif avg_success_rate < 0.6:
                return self.quality_threshold - 0.1  # Lower bar when struggling
            
            return self.quality_threshold
            
        except Exception as e:
            self.logger.error(f"Error calculating dynamic quality threshold: {e}")
            return self.quality_threshold
    
    def _calculate_memory_limit_adjustment(
        self,
        effectiveness_metrics: Dict[MemoryPattern, MemoryEffectivenessMetrics]
    ) -> int:
        """Calculate adjustment to memory retrieval limits."""
        try:
            if not effectiveness_metrics:
                return 0
            
            high_performers = len([m for m in effectiveness_metrics.values() if m.success_rate > 0.8])
            low_performers = len([m for m in effectiveness_metrics.values() if m.success_rate < 0.5])
            
            # Increase limit if many high performers, decrease if many low performers
            if high_performers > low_performers:
                return min(5, high_performers - low_performers)
            else:
                return max(-3, high_performers - low_performers)
            
        except Exception as e:
            self.logger.error(f"Error calculating memory limit adjustment: {e}")
            return 0
    
    def _calculate_recommendation_confidence(
        self,
        effectiveness_metrics: Dict[MemoryPattern, MemoryEffectivenessMetrics]
    ) -> float:
        """Calculate confidence in recommendations."""
        try:
            if not effectiveness_metrics:
                return 0.5
            
            # Base confidence on sample sizes and variance
            total_usage = sum(m.usage_count for m in effectiveness_metrics.values())
            success_rates = [m.success_rate for m in effectiveness_metrics.values()]
            
            # Higher confidence with more data and consistent patterns
            data_confidence = min(1.0, total_usage / 100.0)
            consistency_confidence = 1.0 - (stdev(success_rates) if len(success_rates) > 1 else 0.0)
            
            return (data_confidence + consistency_confidence) / 2.0
            
        except Exception as e:
            self.logger.error(f"Error calculating recommendation confidence: {e}")
            return 0.5
    
    def _default_recommendations(self) -> Dict[str, Any]:
        """Return default recommendations when analysis fails."""
        return {
            'boost_patterns': [MemoryPattern.CONVERSATION_HISTORY, MemoryPattern.EMOTIONAL_CONTEXT],
            'penalty_patterns': [],
            'retrieve_more': [MemoryPattern.CONVERSATION_HISTORY],
            'retrieve_less': [],
            'quality_threshold': self.quality_threshold,
            'memory_limit_adjustment': 0,
            'analysis_timestamp': datetime.now(),
            'confidence': 0.5
        }


# Factory function for dependency injection
def create_memory_effectiveness_analyzer(
    memory_manager=None, 
    trend_analyzer=None, 
    temporal_client=None
) -> MemoryEffectivenessAnalyzer:
    """
    Factory function to create MemoryEffectivenessAnalyzer instance.
    
    Args:
        memory_manager: Vector memory system instance
        trend_analyzer: TrendWise InfluxDB analyzer
        temporal_client: InfluxDB client for metrics storage
        
    Returns:
        Configured MemoryEffectivenessAnalyzer instance
    """
    return MemoryEffectivenessAnalyzer(
        memory_manager=memory_manager,
        trend_analyzer=trend_analyzer,
        temporal_client=temporal_client
    )