# WhisperEngine - Containerized Deployment (Single Assistant)
# No source code required - uses pre-built Docker Hub images
# Uses :latest tags for automatic updates
# 
# Project: whisperengine-containerized (separate from multi-bot: whisperengine-multi)
# Network: whisperengine-containerized-network
# Ports: 8000-8999 range (no conflicts with multi-bot 5000-5999, 9000-9999 range)

services:
  # Database migration init container (runs once before bot starts)
  db-migrate:
    image: whisperengine/whisperengine:latest
    container_name: whisperengine-containerized-db-migrate
    entrypoint: []  # Override entrypoint to prevent main app startup
    command: ["python", "/app/scripts/run_migrations.py"]
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=whisperengine
      - POSTGRES_PASSWORD=whisperengine_password
      - POSTGRES_DB=whisperengine
    networks:
      - whisperengine-containerized-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"  # Only run once
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
        tag: "db-migrate-{.ImageName}-{.Name}-{.ID}"

  # Main WhisperEngine Assistant (AI Chat API)
  whisperengine-assistant:
    image: whisperengine/whisperengine:latest
    container_name: whisperengine-containerized-assistant
    entrypoint: []  # Override broken entrypoint from Dockerfile
    command: ["python", "/app/run.py"]  # Use run.py as the main entry point
    ports:
      - "8090:9090"  # Chat API endpoint (containerized: 8090, multi-bot: 9090-9099)
    environment:
      # Core infrastructure
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=whisperengine
      - POSTGRES_PASSWORD=whisperengine_password
      - POSTGRES_DB=whisperengine
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION_NAME=whisperengine_memory_assistant
      
      # Bot configuration
      - DISCORD_BOT_NAME=assistant
      - CHARACTER_NAME=assistant
      - HEALTH_CHECK_PORT=9090
      
      # LLM Configuration (set in .env file)
      - LLM_CLIENT_TYPE=${LLM_CLIENT_TYPE:-openrouter}
      - LLM_CHAT_API_URL=${LLM_CHAT_API_URL:-https://openrouter.ai/api/v1}
      - LLM_CHAT_MODEL=${LLM_CHAT_MODEL:-anthropic/claude-3-haiku}
      - LLM_CHAT_API_KEY=${LLM_CHAT_API_KEY:-}
      
      # Discord (optional - only if token provided)
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
      - ENABLE_DISCORD=${ENABLE_DISCORD:-false}
      
      # Memory and intelligence
      - MEMORY_SYSTEM_TYPE=vector
      - ENABLE_CHARACTER_INTELLIGENCE=true
      - ENABLE_EMOTIONAL_INTELLIGENCE=true
      
      # InfluxDB (Temporal Intelligence & Machine Learning)
      - INFLUXDB_URL=${INFLUXDB_URL:-http://influxdb:8086}
      - INFLUXDB_TOKEN=${INFLUXDB_TOKEN:-whisperengine-fidelity-first-metrics-token}
      - INFLUXDB_ORG=${INFLUXDB_ORG:-whisperengine}
      - INFLUXDB_BUCKET=${INFLUXDB_BUCKET:-performance_metrics}
      
      # Pre-downloaded model cache paths
      - FASTEMBED_CACHE_PATH=/app/cache/fastembed
      - HF_HOME=/app/cache/huggingface
      - TRANSFORMERS_CACHE=/app/cache/huggingface
      - MODEL_CACHE_DIR=/app/models
      
      # Model configuration (models are pre-downloaded in container)
      - ROBERTA_EMOTION_MODEL_NAME=cardiffnlp/twitter-roberta-base-emotion-multilabel-latest
      - EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
      
    env_file:
      - .env
    volumes:
      - whisperengine_containerized_logs:/app/logs
    networks:
      - whisperengine-containerized-network
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      db-migrate:
        condition: service_completed_successfully
      influxdb:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
        tag: "assistant-{.ImageName}-{.Name}-{.ID}"

  # CDL Web UI for character creation and management
  cdl-web-ui:
    image: whisperengine/whisperengine-ui:latest
    container_name: whisperengine-containerized-web-ui
    ports:
      - "8001:3000"  # Web interface (containerized: 8001, multi-bot: 3001)
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
      # Standard PG* variables (for compatibility)
      - PGHOST=postgres
      - PGPORT=5432
      - PGDATABASE=whisperengine
      - PGUSER=whisperengine
      - PGPASSWORD=whisperengine_password
      # POSTGRES_* variables (what the CDL Web UI actually expects)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=whisperengine
      - POSTGRES_USER=whisperengine
      - POSTGRES_PASSWORD=whisperengine_password
      # Database URL for Node.js applications (alternative to PG* vars)
      - DATABASE_URL=postgresql://whisperengine:whisperengine_password@postgres:5432/whisperengine
      # API endpoint for bot management
      - WHISPERENGINE_API_URL=http://whisperengine-assistant:9090
    networks:
      - whisperengine-containerized-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.2'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
        tag: "web-ui-{.ImageName}-{.Name}-{.ID}"

  # PostgreSQL Database
  postgres:
    image: postgres:16.4-alpine
    container_name: whisperengine-containerized-postgres
    environment:
      - POSTGRES_DB=whisperengine
      - POSTGRES_USER=whisperengine
      - POSTGRES_PASSWORD=whisperengine_password
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    # No external ports - internal access only for production security
    volumes:
      - postgres_containerized_data:/var/lib/postgresql/data
      # SQL init scripts will be included in the assistant image and run via application
    networks:
      - whisperengine-containerized-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.2'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U whisperengine -d whisperengine"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "25m"
        max-file: "3"
        tag: "postgres-{.ImageName}-{.Name}-{.ID}"

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:v1.15.4
    container_name: whisperengine-containerized-qdrant
    # No external ports - internal access only for production security
    volumes:
      - qdrant_containerized_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks:
      - whisperengine-containerized-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.2'
    # Health check disabled - Qdrant containers have minimal tooling
    # Application will retry connections if Qdrant isn't ready yet
    logging:
      driver: "json-file"
      options:
        max-size: "25m"
        max-file: "3"
        tag: "qdrant-{.ImageName}-{.Name}-{.ID}"

  # InfluxDB Time-Series Database (Temporal Intelligence & Machine Learning)
  influxdb:
    image: influxdb:2.7-alpine
    container_name: whisperengine-containerized-influxdb
    ports:
      - "8086:8086"  # InfluxDB UI access (containerized: 8086, multi-bot: 8087)
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USER:-admin}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PASSWORD:-whisperengine_metrics}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG:-whisperengine}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET:-performance_metrics}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_TOKEN:-whisperengine-fidelity-first-metrics-token}
    env_file:
      - .env
    volumes:
      - influxdb_containerized_data:/var/lib/influxdb2
      - influxdb_containerized_config:/etc/influxdb2
    networks:
      - whisperengine-containerized-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.2'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "25m"
        max-file: "3"
        tag: "influxdb-{.ImageName}-{.Name}-{.ID}"

volumes:
  postgres_containerized_data:
    name: whisperengine-containerized_postgres_data
  qdrant_containerized_data:
    name: whisperengine-containerized_qdrant_data
  influxdb_containerized_data:
    name: whisperengine-containerized_influxdb_data
  influxdb_containerized_config:
    name: whisperengine-containerized_influxdb_config
  whisperengine_containerized_logs:
    name: whisperengine-containerized_logs

networks:
  whisperengine-containerized-network:
    name: whisperengine-containerized-network
    driver: bridge
    internal: false  # External access needed for LLM APIs
    ipam:
      config:
        - subnet: 172.20.0.0/16