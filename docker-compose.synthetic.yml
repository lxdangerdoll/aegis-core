version: '3.8'

services:
  # Synthetic conversation generator
  synthetic-generator:
    build:
      context: .
      dockerfile: Dockerfile.synthetic
    volumes:
      - ./synthetic_conversations:/app/synthetic_conversations
      - ./synthetic_validation_report.json:/app/synthetic_validation_report.json
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
      # LM Studio Configuration (DISABLED - using reliable templates instead)
      - LLM_CHAT_API_URL=http://host.docker.internal:1234/v1
      - LLM_CLIENT_TYPE=lmstudio
      - LLM_CHAT_MODEL=local-model  # Uses whatever model is loaded in LM Studio
      - LLM_CHAT_API_KEY=
      - SYNTHETIC_USE_LLM=false  # Disabled for consistent, deterministic results
      - LLM_MAX_TOKENS_CHAT=2048  # Increased for better response generation
      # Bot endpoints (adjust based on your setup)
      - ELENA_ENDPOINT=http://host.docker.internal:9091
      - MARCUS_ENDPOINT=http://host.docker.internal:9092
      - RYAN_ENDPOINT=http://host.docker.internal:9093
      - DREAM_ENDPOINT=http://host.docker.internal:9094
      - GABRIEL_ENDPOINT=http://host.docker.internal:9095
      - SOPHIA_ENDPOINT=http://host.docker.internal:9096
      - JAKE_ENDPOINT=http://host.docker.internal:9097
      - DOTTY_ENDPOINT=http://host.docker.internal:9098
      - AETHERIS_ENDPOINT=http://host.docker.internal:9099
      - AETHYS_ENDPOINT=http://host.docker.internal:3007
      # InfluxDB integration (use existing WhisperEngine InfluxDB)
      - INFLUXDB_URL=http://host.docker.internal:8086
      - INFLUXDB_TOKEN=whisperengine-fidelity-first-metrics-token
      - INFLUXDB_ORG=whisperengine
      - INFLUXDB_BUCKET=performance_metrics
    restart: unless-stopped
    networks:
      - synthetic-network
    healthcheck:
      test: ["CMD", "python", "-c", "print('Generator healthy')"]
      interval: 60s
      timeout: 10s
      retries: 3

  # Validation metrics collector (runs every 4 hours to update InfluxDB)
  synthetic-validator:
    build:
      context: .
      dockerfile: Dockerfile.synthetic
    command: ["sh", "-c", "while true; do python synthetic_validation_metrics.py; sleep 14400; done"]
    volumes:
      - ./synthetic_conversations:/app/synthetic_conversations
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
      # LM Studio Configuration for Enhanced Synthetic Generation
      - LLM_CHAT_API_URL=http://host.docker.internal:1234/v1
      - LLM_CLIENT_TYPE=lmstudio
      - LLM_CHAT_MODEL=local-model
      - LLM_CHAT_API_KEY=
      - SYNTHETIC_USE_LLM=true
      - LLM_MAX_TOKENS_CHAT=1024
      # InfluxDB integration (same as WhisperEngine)
      - INFLUXDB_URL=http://host.docker.internal:8086
      - INFLUXDB_TOKEN=whisperengine-fidelity-first-metrics-token
      - INFLUXDB_ORG=whisperengine
      - INFLUXDB_BUCKET=performance_metrics
    restart: unless-stopped
    networks:
      - synthetic-network

networks:
  synthetic-network:
    driver: bridge