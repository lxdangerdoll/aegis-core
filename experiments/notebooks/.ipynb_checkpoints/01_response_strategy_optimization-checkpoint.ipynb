{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01229880",
   "metadata": {},
   "source": [
    "# Response Strategy Optimization - WhisperEngine ML Experiment 01\n",
    "\n",
    "**Goal**: Train a model to predict optimal response strategies based on user engagement patterns.\n",
    "\n",
    "**Training Data**: InfluxDB conversation quality metrics (13,183 records over 30 days)\n",
    "\n",
    "**Expected Performance**:\n",
    "- 75-85% accuracy with synthetic training data\n",
    "- 80-85% accuracy with synthetic + augmented real user data\n",
    "- **Achieved**: 98.9% accuracy with XGBoost on real data\n",
    "\n",
    "**GPU Support**:\n",
    "- Auto-detects Apple Silicon (MPS), NVIDIA (CUDA), or CPU\n",
    "- XGBoost/LightGBM can leverage GPU acceleration\n",
    "- Random Forest remains CPU-only (scikit-learn doesn't support GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee52143",
   "metadata": {},
   "source": [
    "## Setup: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e430d4c",
   "metadata": {},
   "source": [
    "## GPU Auto-Detection\n",
    "\n",
    "Automatically detect if GPU is available (Apple Silicon MPS, NVIDIA CUDA, or fallback to CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad94ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_gpu():\n",
    "    \"\"\"Auto-detect available GPU and return device configuration\"\"\"\n",
    "    \n",
    "    # Check for Apple Silicon (MPS)\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"‚úÖ Detected: Apple Silicon GPU (MPS)\")\n",
    "            return \"mps\", \"cpu_hist\"  # XGBoost uses 'cpu_hist' for Apple Silicon\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Check for NVIDIA GPU (CUDA)\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            print(f\"‚úÖ Detected: NVIDIA GPU - {gpu_name}\")\n",
    "            return \"cuda\", \"gpu_hist\"  # XGBoost uses 'gpu_hist' for CUDA\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to CPU\n",
    "    print(\"‚ÑπÔ∏è  No GPU detected - using CPU\")\n",
    "    return \"cpu\", \"hist\"  # XGBoost uses 'hist' for CPU\n",
    "\n",
    "# Auto-detect GPU\n",
    "GPU_DEVICE, XGBOOST_TREE_METHOD = detect_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e3df4",
   "metadata": {},
   "source": [
    "## Step 1: Connect to InfluxDB\n",
    "\n",
    "WhisperEngine stores conversation quality metrics in InfluxDB:\n",
    "- `engagement_score`: How engaged the user was (0-1)\n",
    "- `satisfaction_score`: User satisfaction with bot response (0-1)\n",
    "- `coherence_score`: Conversation flow quality (0-1)\n",
    "- `response_time`: Bot response latency (ms)\n",
    "- `token_count`: Number of tokens in bot response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b02c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_influxdb():\n",
    "    \"\"\"Connect to WhisperEngine InfluxDB to query conversation metrics\"\"\"\n",
    "    \n",
    "    # Use localhost when running outside Docker, influxdb hostname when inside Docker\n",
    "    influxdb_host = os.getenv(\"INFLUXDB_HOST\", \"localhost\")\n",
    "    influxdb_port = os.getenv(\"INFLUXDB_PORT\", \"8087\")  # External port\n",
    "    \n",
    "    client = InfluxDBClient(\n",
    "        url=f\"http://{influxdb_host}:{influxdb_port}\",\n",
    "        token=\"whisperengine-fidelity-first-metrics-token\",\n",
    "        org=\"whisperengine\"\n",
    "    )\n",
    "    \n",
    "    return client, client.query_api()\n",
    "\n",
    "# Connect to InfluxDB\n",
    "influx_client, query_api = connect_to_influxdb()\n",
    "print(\"‚úÖ Connected to InfluxDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbc927",
   "metadata": {},
   "source": [
    "## Step 2: Query Training Data\n",
    "\n",
    "Pull 30 days of conversation quality metrics from InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54845bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_conversation_quality_data(query_api, days_back=30):\n",
    "    \"\"\"\n",
    "    Query conversation quality metrics from InfluxDB\n",
    "    \n",
    "    Returns DataFrame with:\n",
    "    - user_id\n",
    "    - bot_name\n",
    "    - timestamp\n",
    "    - engagement_score (0-1)\n",
    "    - satisfaction_score (0-1)\n",
    "    - coherence_score (0-1)\n",
    "    - response_time (ms)\n",
    "    - token_count\n",
    "    \"\"\"\n",
    "    \n",
    "    flux_query = f'''\n",
    "    from(bucket: \"performance_metrics\")\n",
    "      |> range(start: -{days_back}d)\n",
    "      |> filter(fn: (r) => r._measurement == \"conversation_quality\")\n",
    "      |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    '''\n",
    "    \n",
    "    print(f\"Querying InfluxDB for last {days_back} days of conversation data...\")\n",
    "    result = query_api.query_data_frame(flux_query)\n",
    "    \n",
    "    if result.empty:\n",
    "        print(\"‚ö†Ô∏è  No data found in InfluxDB!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Clean up column names\n",
    "    result = result.rename(columns={'_time': 'timestamp'})\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(result)} conversation records\")\n",
    "    return result\n",
    "\n",
    "# Query data\n",
    "df = query_conversation_quality_data(query_api, days_back=30)\n",
    "\n",
    "# Display sample\n",
    "if not df.empty:\n",
    "    print(\"\\nüìä Sample of raw data:\")\n",
    "    display(df.head())\n",
    "    print(f\"\\nüìà Data shape: {df.shape}\")\n",
    "    print(f\"\\nüìÖ Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd5b6b",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering\n",
    "\n",
    "Transform raw metrics into ML-ready features:\n",
    "- **Time-based features**: hour of day, day of week\n",
    "- **Moving averages**: 7-day trends in engagement/satisfaction\n",
    "- **Trend features**: 3-message trends to detect improving/declining patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f150f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create ML features from raw conversation metrics\n",
    "    \n",
    "    Features created:\n",
    "    - hour: Hour of day (0-23)\n",
    "    - day_of_week: Day of week (0=Monday, 6=Sunday)\n",
    "    - engagement_score_ma7: 7-message moving average of engagement\n",
    "    - satisfaction_score_ma7: 7-message moving average of satisfaction\n",
    "    - engagement_score_trend3: 3-message trend (improving/declining)\n",
    "    - satisfaction_score_trend3: 3-message trend\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîß Engineering features...\")\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Time-based features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    \n",
    "    # Sort by user and time for rolling calculations\n",
    "    df = df.sort_values(['user_id', 'timestamp'])\n",
    "    \n",
    "    # Per-user rolling statistics (7-message window)\n",
    "    for col in ['engagement_score', 'satisfaction_score', 'coherence_score']:\n",
    "        df[f'{col}_ma7'] = df.groupby('user_id')[col].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Trend features (3-message window) - detecting improvement/decline\n",
    "    for col in ['engagement_score', 'satisfaction_score']:\n",
    "        df[f'{col}_trend3'] = df.groupby('user_id')[col].transform(\n",
    "            lambda x: x.diff().rolling(window=3, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Fill NaN values with 0 (for first messages without history)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    print(f\"‚úÖ Created {df.shape[1]} features\")\n",
    "    return df\n",
    "\n",
    "# Engineer features\n",
    "if not df.empty:\n",
    "    df_features = engineer_features(df)\n",
    "    \n",
    "    print(\"\\nüìä Sample of engineered features:\")\n",
    "    feature_cols = ['hour', 'day_of_week', 'engagement_score_ma7', \n",
    "                    'satisfaction_score_ma7', 'engagement_score_trend3']\n",
    "    display(df_features[feature_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce49e8c",
   "metadata": {},
   "source": [
    "## Step 4: Create Target Labels\n",
    "\n",
    "Define what \"effective response strategy\" means:\n",
    "- **Label = 1** (Effective): High engagement (>0.7) AND high satisfaction (>0.7)\n",
    "- **Label = 0** (Needs improvement): Otherwise\n",
    "\n",
    "This creates a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_labels(df, engagement_threshold=0.7, satisfaction_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Create binary target: effective_strategy\n",
    "    \n",
    "    Label = 1: engagement > threshold AND satisfaction > threshold\n",
    "    Label = 0: Otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    df['effective_strategy'] = (\n",
    "        (df['engagement_score'] > engagement_threshold) & \n",
    "        (df['satisfaction_score'] > satisfaction_threshold)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = df['effective_strategy'].value_counts()\n",
    "    print(f\"\\nüìä Target distribution:\")\n",
    "    print(f\"   Effective (1): {class_counts.get(1, 0)} samples ({class_counts.get(1, 0)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   Needs improvement (0): {class_counts.get(0, 0)} samples ({class_counts.get(0, 0)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create targets\n",
    "if not df.empty:\n",
    "    df_features = create_target_labels(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de70e2",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "Train XGBoost model with GPU support (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_response_strategy_model(df, algorithm=\"xgboost\", use_gpu=True):\n",
    "    \"\"\"\n",
    "    Train model to predict effective response strategies\n",
    "    \n",
    "    Algorithms:\n",
    "    - random_forest: CPU-only, excellent interpretability\n",
    "    - xgboost: GPU-aware, best accuracy (98.9%)\n",
    "    - lightgbm: GPU-aware, fast for large datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = [\n",
    "        'hour', 'day_of_week',\n",
    "        'engagement_score', 'satisfaction_score', 'coherence_score',\n",
    "        'response_time', 'token_count',\n",
    "        'engagement_score_ma7', 'satisfaction_score_ma7', 'coherence_score_ma7',\n",
    "        'engagement_score_trend3', 'satisfaction_score_trend3'\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y = df['effective_strategy']\n",
    "    \n",
    "    # Train/test split (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüéØ Training {algorithm} model...\")\n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Train model based on algorithm\n",
    "    if algorithm == \"random_forest\":\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Use all CPU cores\n",
    "        )\n",
    "    \n",
    "    elif algorithm == \"xgboost\":\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        # Configure XGBoost device\n",
    "        if use_gpu and GPU_DEVICE == \"cuda\":\n",
    "            device = \"cuda\"\n",
    "            tree_method = \"gpu_hist\"\n",
    "            print(f\"   Using GPU: NVIDIA CUDA\")\n",
    "        elif use_gpu and GPU_DEVICE == \"mps\":\n",
    "            device = \"cpu\"  # XGBoost doesn't support MPS yet\n",
    "            tree_method = \"hist\"\n",
    "            print(f\"   Note: XGBoost doesn't support Apple Silicon GPU yet, using CPU\")\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "            tree_method = \"hist\"\n",
    "            print(f\"   Using CPU\")\n",
    "        \n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            device=device,\n",
    "            tree_method=tree_method,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    elif algorithm == \"lightgbm\":\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        device_type = \"gpu\" if use_gpu and GPU_DEVICE in [\"cuda\", \"mps\"] else \"cpu\"\n",
    "        print(f\"   Using device: {device_type}\")\n",
    "        \n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            device=device_type,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training complete!\")\n",
    "    print(f\"   Train accuracy: {train_score*100:.2f}%\")\n",
    "    print(f\"   Test accuracy: {test_score*100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nüìä Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Needs improvement', 'Effective']))\n",
    "    \n",
    "    return model, X_test, y_test, y_pred, feature_cols\n",
    "\n",
    "# Train model\n",
    "if not df.empty:\n",
    "    model, X_test, y_test, y_pred, feature_cols = train_response_strategy_model(\n",
    "        df_features, \n",
    "        algorithm=\"xgboost\",\n",
    "        use_gpu=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663d2a0",
   "metadata": {},
   "source": [
    "## Step 6: Feature Importance Analysis\n",
    "\n",
    "Understand which features are most important for predicting effective strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_cols, top_n=15):\n",
    "    \"\"\"Visualize feature importance\"\"\"\n",
    "    \n",
    "    # Get feature importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Model doesn't have feature_importances_ attribute\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=importance_df.head(top_n), x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'Top {top_n} Most Important Features for Response Strategy Prediction', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top features\n",
    "    print(f\"\\nüèÜ Top {top_n} Features:\")\n",
    "    for i, row in importance_df.head(top_n).iterrows():\n",
    "        print(f\"   {row['feature']:30s} {row['importance']*100:6.2f}%\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Plot feature importance\n",
    "if not df.empty:\n",
    "    importance_df = plot_feature_importance(model, feature_cols, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8dc04",
   "metadata": {},
   "source": [
    "## Step 7: Confusion Matrix\n",
    "\n",
    "Visualize prediction accuracy across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Needs improvement', 'Effective'],\n",
    "                yticklabels=['Needs improvement', 'Effective'])\n",
    "    plt.title('Confusion Matrix: Response Strategy Predictions', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "if not df.empty:\n",
    "    plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d028160",
   "metadata": {},
   "source": [
    "## Step 8: Save Model\n",
    "\n",
    "Save trained model for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, algorithm=\"xgboost\"):\n",
    "    \"\"\"Save trained model to disk\"\"\"\n",
    "    \n",
    "    model_dir = Path('experiments/models')\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = model_dir / f\"response_strategy_{algorithm}_{timestamp}.pkl\"\n",
    "    \n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"\\nüíæ Model saved: {model_path}\")\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "# Save model\n",
    "if not df.empty:\n",
    "    model_path = save_model(model, algorithm=\"xgboost\")\n",
    "    print(f\"\\n‚úÖ Experiment complete!\")\n",
    "    print(f\"\\nüìà Summary:\")\n",
    "    print(f\"   - Training samples: {len(df_features)}\")\n",
    "    print(f\"   - Test accuracy: {model.score(X_test, y_test)*100:.2f}%\")\n",
    "    print(f\"   - Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244eaac5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**Experiment with different approaches:**\n",
    "1. Try different algorithms (Random Forest, LightGBM)\n",
    "2. Adjust thresholds for \"effective strategy\" label\n",
    "3. Add more features (user personality traits, conversation history length)\n",
    "4. Test with different time windows (7-day vs 14-day moving averages)\n",
    "\n",
    "**Integration into WhisperEngine:**\n",
    "1. Deploy model as prediction service\n",
    "2. Use predictions to select CDL conversation modes\n",
    "3. Monitor prediction accuracy in production\n",
    "4. Retrain periodically with new data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
