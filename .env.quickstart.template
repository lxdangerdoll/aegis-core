# WhisperEngine Quick Start Configuration
# Copy this file to .env and customize the settings below

# ===========================================
# LLM Configuration (REQUIRED)
# ===========================================
# Default: Use local LM Studio (recommended for getting started)
LLM_CLIENT_TYPE=lmstudio
LLM_CHAT_API_URL=http://host.docker.internal:1234/v1
LLM_CHAT_MODEL=local-model
LLM_CHAT_API_KEY=

# Alternative: Use OpenRouter (requires API key)
# LLM_CLIENT_TYPE=openrouter
# LLM_CHAT_API_URL=https://openrouter.ai/api/v1
# LLM_CHAT_MODEL=mistralai/mistral-medium-3.1
# LLM_CHAT_API_KEY=your_api_key_here

# Alternative: Use OpenAI
# LLM_CLIENT_TYPE=openai
# LLM_CHAT_API_URL=https://api.openai.com/v1
# LLM_CHAT_MODEL=gpt-4o-mini
# LLM_CHAT_API_KEY=sk-your_openai_key

# Alternative: Use Ollama
# LLM_CLIENT_TYPE=ollama
# LLM_CHAT_API_URL=http://host.docker.internal:11434/v1
# LLM_CHAT_MODEL=llama3.1:8b
# LLM_CHAT_API_KEY=


# Bot settings
DISCORD_BOT_NAME=assistant
CHARACTER_NAME=assistant
HEALTH_CHECK_PORT=9090


# ===========================================
# Discord Integration (OPTIONAL)
# ===========================================
# Leave empty to disable Discord integration
# Set DISCORD_BOT_TOKEN to enable Discord bot
DISCORD_BOT_TOKEN=
ENABLE_DISCORD=false

# ===========================================
# Advanced Settings (Optional)
# ===========================================
# Database settings (use defaults unless you know what you're doing)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=whisperengine
POSTGRES_PASSWORD=whisperengine_password
POSTGRES_DB=whisperengine

# Vector database settings
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=whisperengine_memory_assistant

# InfluxDB (Temporal Intelligence & Machine Learning)
INFLUXDB_URL=http://influxdb:8086
INFLUXDB_TOKEN=whisperengine-fidelity-first-metrics-token
INFLUXDB_ORG=whisperengine
INFLUXDB_BUCKET=performance_metrics
INFLUXDB_USER=admin
INFLUXDB_PASSWORD=whisperengine_metrics

# Pre-downloaded Model Settings (models are bundled in container)
# These models are pre-downloaded during container build for instant startup
FASTEMBED_CACHE_PATH=/app/cache/fastembed
HF_HOME=/app/cache/huggingface
TRANSFORMERS_CACHE=/app/cache/huggingface
MODEL_CACHE_DIR=/app/models

# Model Selection (pre-downloaded models)
ROBERTA_EMOTION_MODEL_NAME=cardiffnlp/twitter-roberta-base-emotion-multilabel-latest
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

